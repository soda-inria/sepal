{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SEPAL to embed Mini YAGO3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykeen\n",
    "import torch\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "sys.path.append('../sepal')\n",
    "from knowledge_graph import KnowledgeGraph\n",
    "from settings import set_control_params\n",
    "from dataloader import DataLoader\n",
    "from downstream_evaluation import prediction_scores, RW_PATH\n",
    "from sepal import run_sepal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mini YAGO3 dataset is constructed from YAGO3 [1] by first filtering for entities with a degree of 9 or greater, and then selecting the largest connected component from the resulting subgraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples_dir = Path(\"../data/knowledge_graphs/mini_yago3\")\n",
    "data_loader = DataLoader(triples_dir)\n",
    "triples_factory = data_loader.get_triples_factory()\n",
    "graph = KnowledgeGraph(triples_factory, name='mini_yago3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the graph is loaded we can print some basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entities: 129493\n",
      "Number of relations: 74\n",
      "Number of triples: 1132010\n",
      "Highest degree: 65711\n",
      "Average degree: 12.6\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of entities: {graph.num_entities}\")\n",
    "print(f\"Number of relations: {graph.num_relations}\")\n",
    "print(f\"Number of triples: {graph.num_triples}\")\n",
    "print(f\"Highest degree: {graph.degrees.max():.0f}\")\n",
    "print(f\"Average degree: {graph.degrees.mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check if the graph is connected or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of connected components: 1\n",
      "Largest connected component contains 100.00% of all the nodes.\n"
     ]
    }
   ],
   "source": [
    "n_components, labels = scipy.sparse.csgraph.connected_components(\n",
    "    graph.adjacency, directed=False, return_labels=True\n",
    ")\n",
    "largest_cc = np.where(labels == np.argmax(np.bincount(labels)))[0]\n",
    "print(f\"Number of connected components: {n_components}\")\n",
    "print(f\"Largest connected component contains {len(largest_cc) / graph.num_entities:.2%} of all the nodes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running SEPAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we specify the hyperparameters. Here, we use SEPAL with DistMult [2] as base model.\n",
    "\n",
    "Since the input graph is connected, we can use `handle_disconnected=False` (this will skip some connectedness checks and make the method slightly faster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" # Change to the device you want to use, e.g., \"cpu\" or \"cuda:1\"\n",
    "print(f\"Using device: {device}\")\n",
    "params = {\n",
    "    \"embed_dim\": 100,\n",
    "    \"subgraph_max_size\": 4e4,\n",
    "    \"embed_method\": \"distmult\",\n",
    "    \"core_node_proportions\": 0.05,  # proportion of nodes to select as core nodes\n",
    "    \"core_selection\": \"degree\",  # \"degree\" or \"hybrid\" or \"pagerank\"\n",
    "    \"diffusion_stop\": 0.8,\n",
    "    \"propagation_lr\": 1,\n",
    "    \"n_propagation_steps\": 10,\n",
    "    \"num_epochs\": 50,\n",
    "    \"batch_size\": 512,\n",
    "    \"num_negs_per_pos\": 1,\n",
    "    \"handle_disconnected\": False, # since our graph is connected\n",
    "    \"seed\": 0,\n",
    "}\n",
    "ctrl = set_control_params(device=device, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can train the model in less than a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central core extraction:\n",
      "Core subgraph contains 4498 entities (3.5% of total graph)\n",
      "Assigning super-spreaders' neighbors...\n",
      "59.4% assigned\n",
      "Diffusion on the graph...\n",
      "80.0% assigned\n",
      "Merging subgraphs...\n",
      "27 subgraphs before merging.\n",
      "6 subgraphs after merging.\n",
      "Subgraph dilation...\n",
      "0 remaining         \n",
      "Merging small subgraphs...\n",
      "Splitting large subgraphs...\n",
      "5 subgraphs before merging.\n",
      "5 subgraphs after merging.\n",
      "Subgraph sizes: min: 27975, max: 38427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs on cuda:0: 100%|██████████| 50/50 [00:47<00:00,  1.06epoch/s, loss=0.235, prev_loss=0.239]\n",
      "Propagating through subgraphs: 100%|██████████| 5/5 [00:01<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 50.41 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings, relation_embeddings, sepal_time = run_sepal(ctrl, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory if it doesn't exist\n",
    "output_dir = Path(\"../embeddings\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.savez_compressed(\n",
    "    output_dir / \"mini_yago3_sepal_embeddings.npz\",\n",
    "    entity_embeddings=embeddings.cpu().numpy(),\n",
    "    relation_embeddings=relation_embeddings.cpu().numpy(),\n",
    "    time=sepal_time,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with DistMult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a baseline, we now train a DistMult model on the full graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs on cuda:0: 100%|██████████| 50/50 [23:25<00:00, 28.12s/epoch, loss=0.518, prev_loss=0.523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistMult training time: 1406.22 seconds\n"
     ]
    }
   ],
   "source": [
    "# Initialize DistMult model\n",
    "model = pykeen.models.DistMult(\n",
    "    triples_factory=graph.triples_factory,\n",
    "    random_seed=0,\n",
    "    embedding_dim=100,\n",
    "    loss=\"CrossEntropyLoss\",\n",
    ").to(device)\n",
    "\n",
    "# Set up training loop\n",
    "training_loop = pykeen.training.SLCWATrainingLoop(\n",
    "    model=model,\n",
    "    triples_factory=graph.triples_factory,\n",
    "    optimizer=torch.optim.Adam(params=model.get_grad_params(), lr=1e-3),\n",
    "    negative_sampler_kwargs={\n",
    "        \"num_negs_per_pos\": 1,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Train model\n",
    "start = time()\n",
    "losses = training_loop.train(\n",
    "    triples_factory=graph.triples_factory,\n",
    "    num_epochs=50,\n",
    "    batch_size=512,\n",
    ")\n",
    "end = time()\n",
    "distmult_time = end - start\n",
    "print(f\"DistMult training time: {distmult_time:.2f} seconds\")\n",
    "\n",
    "# Get embeddings for entities and relations\n",
    "distmult_embeddings = model.entity_representations[0]().detach().cpu().numpy()\n",
    "distmult_rel_embed = model.relation_representations[0]().detach().cpu().numpy()\n",
    "\n",
    "# Save the embeddings\n",
    "np.savez_compressed(\n",
    "    \"../embeddings/mini_yago3_distmult_embeddings.npz\",\n",
    "    entity_embeddings=distmult_embeddings,\n",
    "    relation_embeddings=distmult_rel_embed,\n",
    "    time=distmult_time,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that SEPAL is much faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEPAL runs 28x faster than DistMult. SEPAL time: 50 seconds, DistMult time: 23 minutes.\n"
     ]
    }
   ],
   "source": [
    "speedup_ratio = distmult_time / sepal_time\n",
    "\n",
    "print(f\"SEPAL runs {speedup_ratio:.0f}x faster than DistMult. SEPAL time: {sepal_time:.0f} seconds, DistMult time: {distmult_time/60:.0f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on downstream tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate the utility of embeddings for downstream tasks. In the paper we provide 46 downstream tables, 26 for classification and 20 for regression. For this example, let's use the Housing Prices dataset, a regression task on real-world data. The task is to predict the average housing price in US cities, from the embeddings of those cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = prediction_scores(\n",
    "    embeddings,\n",
    "    \"sepal-mini_yago3\",\n",
    "    \"mini_yago3\",\n",
    "    data_loader.entity_to_idx,\n",
    "    RW_PATH / \"housing_prices.parquet\",\n",
    "    \"regression\",\n",
    "    n_repeats=5,\n",
    "    tune_hyperparameters=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEPAL R2 score: 0.139 ± 0.002\n"
     ]
    }
   ],
   "source": [
    "mean_score = results[\"scores\"].mean()\n",
    "std_err = np.std(results[\"scores\"]) / np.sqrt(len(results[\"scores\"]))\n",
    "print(f\"SEPAL R2 score: {mean_score:.3f} ± {std_err:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distmult_results = prediction_scores(\n",
    "    distmult_embeddings,\n",
    "    \"distmult-mini_yago3\",\n",
    "    \"mini_yago3\",\n",
    "    data_loader.entity_to_idx,\n",
    "    RW_PATH / \"housing_prices.parquet\",\n",
    "    \"regression\",\n",
    "    n_repeats=5,\n",
    "    tune_hyperparameters=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistMult R2 score: 0.109 ± 0.002\n"
     ]
    }
   ],
   "source": [
    "mean_score = distmult_results[\"scores\"].mean()\n",
    "std_err = np.std(distmult_results[\"scores\"]) / np.sqrt(len(distmult_results[\"scores\"]))\n",
    "print(f\"DistMult R2 score: {mean_score:.3f} ± {std_err:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R2 score (higher is better) reported above shows that SEPAL outperforms DistMult on this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SEPAL works better on *large* knowledge graphs (> 1M entities).\n",
    "- The partitioning method, BLOCS, is designed for *scale-free* graphs. It may be slower on graphs with other degree distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Farzaneh Mahdisoltani, Joanna Biega, and Fabian Suchanek. [\"Yago3: A knowledge base from multilingual wikipedias\"](https://imt.hal.science/hal-01699874/document). In *7th biennial conference on innovative data systems research*. CIDR Conference, 2014.\n",
    "\n",
    "[2] Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. [\"Embedding entities and relations for learning and inference in knowledge bases\"](https://arxiv.org/pdf/1412.6575). In *Proceedings of the 3rd International Conference on Learning Representations (ICLR)*, 2015."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sepal_public",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
